{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm Example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/migfel/SVM/blob/main/svm_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_MYPWEx9O5E"
      },
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/akshayrb22/playing-with-data/blob/master/supervised_learning/support_vector_machine/svm.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR4tBUTU9O5F"
      },
      "source": [
        "# Support Vector Machine Classification\n",
        "\n",
        "\n",
        "## What will we do?\n",
        "\n",
        "We will build a Support Vector Machine that will find the optimal hyperplane that maximizes the margin between two toy data classes using gradient descent.  \n",
        "\n",
        "![alt text](http://opticalengineering.spiedigitallibrary.org/data/journals/optice/24850/oe_52_2_027003_f005.png \"Logo Title Text 1\")\n",
        "\n",
        "\n",
        "## What are some use cases for SVMs?\n",
        "\n",
        "-Classification, regression (time series prediction, etc) , outlier detection, clustering\n",
        "\n",
        "\n",
        "## How does an SVM compare to other ML algorithms?\n",
        "\n",
        "![alt text](https://image.slidesharecdn.com/mscpresentation-140722065852-phpapp01/95/msc-presentation-bioinformatics-7-638.jpg?cb=1406012610 \"Logo Title Text 1\")\n",
        "\n",
        "- As a rule of thumb, SVMs are great for relatively small data sets with fewer outliers. \n",
        "- Other algorithms (Random forests, deep neural networks, etc.) require more data but almost always come up with very robust models.\n",
        "- The decision of which classifier to use depends on your dataset and the general complexity of the problem.\n",
        "- \"Premature optimization is the root of all evil (or at least most of it) in programming.\" - Donald Knuth, CS Professor (Turing award speech 1974)  \n",
        "\n",
        "\n",
        "## What is a Support Vector Machine?\n",
        "\n",
        "It's a supervised machine learning algorithm which can be used for both classification or regression problems. But it's usually used for classification. Given 2 or more labeled classes of data, it acts as a discriminative classifier, formally defined by an optimal hyperplane that seperates all the classes. New examples that are then mapped into that same space can then be categorized based on on which side of the gap they fall.\n",
        "\n",
        "## What are Support Vectors?\n",
        "\n",
        "![alt text](https://www.dtreg.com/uploaded/pageimg/SvmMargin2.jpg \"Logo Title Text 1\")\n",
        " \n",
        "Support vectors are the data points nearest to the hyperplane, the points of a data set that, if removed, would alter the position of the dividing hyperplane. Because of this, they can be considered the critical elements of a data set, they are what help us build our SVM. \n",
        "\n",
        "## Whats a hyperplane?\n",
        "\n",
        "![alt text](http://slideplayer.com/slide/1579281/5/images/32/Hyperplanes+as+decision+surfaces.jpg \"Logo Title Text 1\")\n",
        "\n",
        "Geometry tells us that a hyperplane is a subspace of one dimension less than its ambient space. For instance, a hyperplane of an n-dimensional space is a flat subset with dimension n − 1. By its nature, it separates the space into two half spaces.\n",
        "\n",
        "## Let's define our loss function (what to minimize) and our objective function (what to optimize)\n",
        "\n",
        "#### Loss function\n",
        "\n",
        "We'll use the Hinge loss. This is a loss function used for training classifiers. The hinge loss is used for \"maximum-margin\" classification, most notably for support vector machines (SVMs).\n",
        "\n",
        "![alt text](http://i.imgur.com/OzCwzyN.png \"Logo Title Text 1\")\n",
        "\n",
        "\n",
        "c is the loss function, x the sample, y is the true label, f(x) the predicted label.\n",
        "\n",
        "![alt text](http://i.imgur.com/FZ7JcG3.png \"Logo Title Text 1\")\n",
        "\n",
        " \n",
        "#### Objective Function\n",
        "\n",
        "![alt text](http://i.imgur.com/I5NNu44.png \"Logo Title Text 1\")\n",
        "\n",
        "As you can see, our objective of a SVM consists of two terms. The first term is a regularizer, the heart of the SVM, the second term the loss. The regularizer balances between margin maximization and loss. We want to find the decision surface that is maximally far away from any data points.\n",
        "\n",
        "How do we minimize our loss/optimize for our objective (i.e learn)?\n",
        "\n",
        "We have to derive our objective function to get the gradients! Gradient descent ftw.  As we have two terms, we will derive them seperately using the sum rule in differentiation.\n",
        "\n",
        "\n",
        "![alt text](http://i.imgur.com/6uK3BnH.png \"Logo Title Text 1\")\n",
        "\n",
        "This means, if we have a misclassified sample, we update the weight vector w using the gradients of both terms, else if classified correctly,we just update w by the gradient of the regularizer.\n",
        "\n",
        "\n",
        "\n",
        "Misclassification condition \n",
        "\n",
        "![alt text](http://i.imgur.com/g9QLAyn.png \"Logo Title Text 1\")\n",
        "\n",
        "Update rule for our weights (misclassified)\n",
        "\n",
        "![alt text](http://i.imgur.com/rkdPpTZ.png \"Logo Title Text 1\")\n",
        "\n",
        "including the learning rate η and the regularizer λ\n",
        "The learning rate is the length of the steps the algorithm makes down the gradient on the error curve.\n",
        "- Learning rate too high? The algorithm might overshoot the optimal point.\n",
        "- Learning rate too low? Could take too long to converge. Or never converge.\n",
        "\n",
        "The regularizer controls the trade off between the achieving a low training error and a low testing error that is the ability to generalize your classifier to unseen data. As a regulizing parameter we choose 1/epochs, so this parameter will decrease, as the number of epochs increases.\n",
        "- Regularizer too high? overfit (large testing error) \n",
        "- Regularizer too low? underfit (large training error) \n",
        "\n",
        "Update rule for our weights (correctly classified)\n",
        "\n",
        "![alt text](http://i.imgur.com/xTKbvZ6.png \"Logo Title Text 1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UqPlHAI9O5F"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "6l0z0x4E9O5F",
        "outputId": "813f9194-ec24-4a24-9f7c-27208068bc94"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/melwinlobo18/K-Nearest-Neighbors/master/Dataset/data.csv'\n",
        "df = pd.read_csv(url)  # Dataset - Breast Cancer Wisconsin Data\n",
        "df['diagnosis'] = df['diagnosis'].map({\n",
        "    'M': 1,\n",
        "    'B': 2\n",
        "})  # Label values - 1 for Malignant and 2 for Benign\n",
        "labels = df['diagnosis'].tolist()\n",
        "df['Class'] = labels  #Cpying values of diagnosis to newly clreated labels column\n",
        "df = df.drop(['id', 'Unnamed: 32', 'diagnosis'],\n",
        "             axis=1)  #Dropping unncessary columns\n",
        "df.head()  #Displaying first five rows of the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  fractal_dimension_worst  Class\n",
              "0        17.99         10.38  ...                  0.11890      1\n",
              "1        20.57         17.77  ...                  0.08902      1\n",
              "2        19.69         21.25  ...                  0.08758      1\n",
              "3        11.42         20.38  ...                  0.17300      1\n",
              "4        20.29         14.34  ...                  0.07678      1\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "LvHYcbpO9O5H",
        "outputId": "8f8b0efe-c69c-4ceb-cda6-eb3a92cce2f0"
      },
      "source": [
        "target_names = ['', 'M', 'B']\n",
        "df['attack_type'] = df.Class.apply(lambda x: target_names[x])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Class</th>\n",
              "      <th>attack_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  Class  attack_type\n",
              "0        17.99         10.38  ...      1            M\n",
              "1        20.57         17.77  ...      1            M\n",
              "2        19.69         21.25  ...      1            M\n",
              "3        11.42         20.38  ...      1            M\n",
              "4        20.29         14.34  ...      1            M\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHQbtwxt9O5H"
      },
      "source": [
        "df1 = df[df.Class == 1]\n",
        "df2 = df[df.Class == 2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "PUIn0W5w9O5H",
        "outputId": "4c58a15c-e43b-4664-bd58-955b12abca19"
      },
      "source": [
        "plt.xlabel('radius_mean')\n",
        "plt.ylabel('texture_mean')\n",
        "plt.scatter(df1['radius_mean'], df1['texture_mean'], color='green', marker='+')\n",
        "plt.scatter(df2['radius_mean'], df2['texture_mean'], color='blue', marker='.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fa11f010e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "oBnnnAG19O5H",
        "outputId": "8e95998c-9940-4eb1-c285-a84d7f816fff"
      },
      "source": [
        "X = df.drop(['Class', 'attack_type'], axis='columns')\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPc7KTi9O5H"
      },
      "source": [
        "y = df.Class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtBvzsQp9O5I"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH1CWuz99O5I"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76J4kntU9O5I"
      },
      "source": [
        "model = SVC(kernel='linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puKFU_Pv9O5I",
        "outputId": "7fc69de4-3be5-420d-e47c-e651680b2f1e"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwr5X3p59O5I",
        "outputId": "1cddcd21-2e05-4d35-c4d3-29878cf21250"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 2 1 2 2 2 2 1 1 1 2 2 1 2 1 2 2 2 1 2 2 1 2 2 2 1 1 1 2 2 1 2 2 2 1\n",
            " 2 1 1 2 2 2 2 1 1 2 1 1 1 2 2 2 2 1 2 1 2 1 1 2 2 2 2 2 2 1 2 2 1 2 2 1 2\n",
            " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 1 1 2 2 2 1 1 1 2 1 2 2 2 1 2 1 2 1 2 2 1 1 2\n",
            " 2 2 1 1 2 2 2 1 1 1 1 2 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 2 2 1 1 2 2 2 2 2 2\n",
            " 2 2 2 1 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzRTSB-K9O5I"
      },
      "source": [
        "percentage = model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCrNX6j09O5I",
        "outputId": "3a341b31-e89e-4e99-b67a-cf6e3c2ffe61"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "res = confusion_matrix(y_test, predictions)\n",
        "print(\"Confusion Matrix\")\n",
        "print(res)\n",
        "print(f\"Test Set: {len(X_test)}\")\n",
        "print(f\"Accuracy = {percentage*100} %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 63   4]\n",
            " [  3 101]]\n",
            "Test Set: 171\n",
            "Accuracy = 95.90643274853801 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}